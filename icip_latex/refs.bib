@article{zadeh2017tensor,
  title={Tensor fusion network for multimodal sentiment analysis},
  author={Zadeh, Amir and Chen, Minghai and Poria, Soujanya and Cambria, Erik and Morency, Louis-Philippe},
  journal={arXiv preprint arXiv:1707.07250},
  year={2017}
}

@inproceedings{williams2018recognizing,
  title={Recognizing emotions in video using multimodal DNN feature fusion},
  author={Williams, Jennifer and Kleinegesse, Steven and Comanescu, Ramona and Radu, Oana},
  booktitle={Grand Challenge and Workshop on Human Multimodal Language},
  pages={11--19},
  year={2018},
  organization={Association for Computational Linguistics}
}

@inproceedings{williams2018dnn,
  title={Dnn multimodal fusion techniques for predicting video sentiment},
  author={Williams, Jennifer and Comanescu, Ramona and Radu, Oana and Tian, Leimin},
  booktitle={Proceedings of grand challenge and workshop on human multimodal language (Challenge-HML)},
  pages={64--72},
  year={2018}
}

@inproceedings{liu2018efficient,
  title={Efficient low-rank multimodal fusion with modality-specific factors},
  author={Liu, Zhun and Shen, Ying and Lakshminarasimhan, Varun Bharadhwaj and Liang, Paul Pu and Zadeh, AmirAli Bagher and Morency, Louis-Philippe},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2247--2256},
  year={2018}
}

@inproceedings{zadeh2018memory,
  title={Memory fusion network for multi-view sequential learning},
  author={Zadeh, Amir and Liang, Paul Pu and Mazumder, Navonil and Poria, Soujanya and Cambria, Erik and Morency, Louis-Philippe},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{zadeh2018multimodal,
  title={Multimodal language analysis in the wild: Cmu-mosei dataset and interpretable dynamic fusion graph},
  author={Zadeh, AmirAli Bagher and Liang, Paul Pu and Poria, Soujanya and Cambria, Erik and Morency, Louis-Philippe},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2236--2246},
  year={2018}
}

@inproceedings{tsai2019learning,
  title={Learning Factorized Multimodal Representations},
  author={Yao-Hung Hubert Tsai and Paul Pu Liang and Amir Zadeh and Louis-Philippe Morency and Ruslan Salakhutdinov},
  booktitle={International Conference on Learning Representations},
  year={2019},
  url={https://openreview.net/forum?id=rygqqsA9KX},
}

@inproceedings{hazarika2020misa,
  title={Misa: Modality-invariant and-specific representations for multimodal sentiment analysis},
  author={Hazarika, Devamanyu and Zimmermann, Roger and Poria, Soujanya},
  booktitle={Proceedings of the 28th ACM international conference on multimedia},
  pages={1122--1131},
  year={2020}
}

@inproceedings{yu2021learning,
  title={Learning modality-specific representations with self-supervised multi-task learning for multimodal sentiment analysis},
  author={Yu, Wenmeng and Xu, Hua and Yuan, Ziqi and Wu, Jiele},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={12},
  pages={10790--10797},
  year={2021}
}

@article{wang2022cross,
  title={Cross-modal enhancement network for multimodal sentiment analysis},
  author={Wang, Di and Liu, Shuai and Wang, Quan and Tian, Yumin and He, Lihuo and Gao, Xinbo},
  journal={IEEE Transactions on Multimedia},
  volume={25},
  pages={4909--4921},
  year={2022},
  publisher={IEEE}
}

@article{wang2023tetfn,
  title={TETFN: A text enhanced transformer fusion network for multimodal sentiment analysis},
  author={Wang, Di and Guo, Xutong and Tian, Yumin and Liu, Jinhui and He, LiHuo and Luo, Xuemei},
  journal={Pattern Recognition},
  volume={136},
  pages={109259},
  year={2023},
  publisher={Elsevier}
}

@article{zhu2024review,
  title={A review of key technologies for emotion analysis using multimodal information},
  author={Zhu, Xianxun and Guo, Chaopeng and Feng, Heyang and Huang, Yao and Feng, Yichen and Wang, Xiangyang and Wang, Rui},
  journal={Cognitive Computation},
  volume={16},
  number={4},
  pages={1504--1530},
  year={2024},
  publisher={Springer}
}

@article{huang2023dominant,
  title={Dominant single-modal supplementary fusion (simsuf) for multimodal sentiment analysis},
  author={Huang, Jian and Ji, Yanli and Qin, Zhen and Yang, Yang and Shen, Heng Tao},
  journal={IEEE Transactions on Multimedia},
  volume={26},
  pages={8383--8394},
  year={2024},
  publisher={IEEE}
}

@article{wang2024dual,
  title={Dual-Perspective Fusion Network for Aspect-Based Multimodal Sentiment Analysis},
  author={Wang, Di and Tian, Changning and Liang, Xiao and Zhao, Lin and He, Lihuo and Wang, Quan},
  journal={IEEE Transactions on Multimedia},
  volume={26},
  pages={4028--4038},
  year={2024},
  publisher={IEEE}
}

@article{jiang2025boosting,
  title={Boosting modal-specific representations for sentiment analysis with incomplete modalities},
  author={Jiang, Xin and He, Lihuo and Gao, Fei and Zhang, Kaifan and Li, Jie and Gao, Xinbo},
  journal={IEEE Transactions on Multimedia},
  year={2025},
  publisher={IEEE}
}

@article{li2025caetfn,
  title={CAETFN: Context adaptively enhanced text-guided fusion network for multimodal sentiment analysis},
  author={Li, Jiabao and Liu, Ruyi and Miao, Qiguang and Wang, Di and Liu, Xiangzeng},
  journal={IEEE Transactions on Affective Computing},
  year={2025},
  publisher={IEEE}
}

@article{wang2025contrastive,
  title={Contrastive-Based Removal of Negative Information in Multimodal Emotion Analysis},
  author={Wang, Rui and Wang, Yaoyang and Cambria, Erik and Fan, Xuhui and Yu, Xiaohan and Huang, Yao and E, Xiaosong and Zhu, Xianxun},
  journal={Cognitive Computation},
  volume={17},
  number={3},
  pages={107},
  year={2025},
  publisher={Springer}
}

@article{hu2024graph,
  title={Graph Reconstruction Attention Fusion Network for Multimodal Sentiment Analysis},
  author={Hu, Ronglong and Yi, Jizheng and Chen, Lijiang and Jin, Ze},
  journal={IEEE Transactions on Industrial Informatics},
  year={2024},
  publisher={IEEE}
}

@article{zhuang2025multi,
  title={Multi-Level Contrastive Learning for Multimodal Sentiment Analysis},
  author={Zhuang, Yan and Bai, Wei and Zhang, Yanru and Deng, Jiawen and Hu, Zheng and Zhang, Xiaoyue and Ren, Fuji},
  journal={IEEE Transactions on Multimedia},
  year={2025},
  publisher={IEEE}
}